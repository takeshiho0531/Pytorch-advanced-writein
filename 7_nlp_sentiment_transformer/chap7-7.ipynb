{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformerの学習・推論、判定根拠の可視化を実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パッケージのインポート\n",
    "import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "#import torchvision\n",
    "#from torchvision import models,transforms\n",
    "import cv2 \n",
    "import time\n",
    "import math\n",
    "from matplotlib import cm\n",
    "\n",
    "import gensim\n",
    "import torchtext\n",
    "#import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderとTransformerモデルの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6_/zpjxt4sx4kn92ky_w1lbwjmr0000gn/T/ipykernel_97336/3418844170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_IMDb_DataLoaders_and_TEXT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/pytorch_advanced/7_nlp_sentiment_transformer/utils/fixing_dataloader.py\u001b[0m in \u001b[0;36mget_IMDb_DataLoaders_and_TEXT\u001b[0;34m(max_length, batch_size)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# torchtext.data.Datasetのsplit関数で訓練データとvalidationデータを分ける\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# torchtextで単語ベクトルとして英語学習済みモデルを読み込みます\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "from utils.fixing_dataloader import get_IMDb_DataLoaders_and_TEXT\n",
    "\n",
    "#読み込み\n",
    "train_dl,val_dl,test_dl,TEXT=get_IMDb_DataLoaders_and_TEXT(max_length=256,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6_/zpjxt4sx4kn92ky_w1lbwjmr0000gn/T/ipykernel_97336/3640881628.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#辞書型オブジェクトにまとめる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "#辞書型オブジェクトにまとめる\n",
    "dataloaders_dict={\"train\":train_dl,\"val\":val_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了\n"
     ]
    }
   ],
   "source": [
    "from utils.transformer import TransformerClassification\n",
    "\n",
    "#モデル構築\n",
    "net=TransformerClassification(text_embedding_vectors=TEXT.vocab.vectors,d_model=300,max_seq_len=256,output_dim=2)\n",
    "\n",
    "#ネットワーク初期化を定義\n",
    "def weights_init(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find(\"Linear\")!=-1:\n",
    "        #Linear層の初期化\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias,0.0)\n",
    "\n",
    "#訓練モードに設定\n",
    "net.train()\n",
    "\n",
    "#TransformerBlockモジュールを初期化実行\n",
    "net.net3_1.apply(weights_init)\n",
    "net.net3_2.apply(weights_init)\n",
    "\n",
    "print(\"ネットワーク設定完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数と最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#損失関数の設定\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "#nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "#最適化手法の設定\n",
    "learning_rate=2e-5\n",
    "optimizer=optim.Adam(net.parameters(),lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8eafc1c3d0ba1f317c23d0e9aa4360a9d8a5b5ceacbb507f9d0793fa2c9bc9e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
